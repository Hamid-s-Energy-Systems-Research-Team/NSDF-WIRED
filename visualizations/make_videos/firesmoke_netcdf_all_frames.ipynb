{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca04e56-fa0e-4840-9981-379cc545ae2a",
   "metadata": {},
   "source": [
    "# Create .PNG images of all timesteps from `idx_calls` loading from netCDF files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac89f1-da13-4a78-b05f-ac4a17fea961",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb7475-1c3d-41ef-92a2-dbaaaba8ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to parallelize frame creation for timesteps\n",
    "import subprocess\n",
    "\n",
    "# for numerical work\n",
    "import numpy as np\n",
    "\n",
    "# for accessing file system\n",
    "import os\n",
    "\n",
    "# for loading netcdf files, for metadata\n",
    "import xarray as xr\n",
    "\n",
    "# Used for processing netCDF time data\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Used for indexing via metadata\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# for exporting the dictionary of issue files at the end of notebook\n",
    "import pickle\n",
    "\n",
    "# Accessory, used to generate progress bar for running for loops\n",
    "# from tqdm.notebook import tqdm\n",
    "# import ipywidgets\n",
    "# import jupyterlab_widgets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40349c30-d1ce-4695-9a01-170824dfb3df",
   "metadata": {},
   "source": [
    "## Get path to original firesmoke data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12053d7-0394-49af-b74d-8d0f9be7ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******* THIS IS WHEN RUNNING FROM ATLANTIS.SCI **************\n",
    "# directory to all netCDF firesmoke data\n",
    "netcdf_dir = firesmoke_dir = \"/usr/sci/cedmav/data/firesmoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a0fb9-fc95-442d-b9eb-4196cc9582f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata of datasets, had to be obtained manually\n",
    "ids = [\"BSC18CA12-01\", \"BSC00CA12-01\", \"BSC06CA12-01\", \"BSC12CA12-01\"]\n",
    "start_dates = [\"20210304\", \"20210304\", \"20210304\", \"20210303\"]\n",
    "end_dates = [\"20240627\", \"20240627\", \"20240627\", \"20240627\"]\n",
    "\n",
    "id_dates = {ids[i]: {\"start_date\": start_dates[i], \"end_date\": end_dates[i]} for i in range(len(ids))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5385e5-517a-45f4-8173-ba27ed77fa0d",
   "metadata": {},
   "source": [
    "### In this section, we load metadata from 381x1041 and 381x1081 files using `xr.open_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01758d7f-16e2-43ab-a47a-d8503bb1b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to small and big files\n",
    "file_s = f'{netcdf_dir}/{ids[1]}/dispersion_20210304.nc'\n",
    "file_b = f'{netcdf_dir}/{ids[1]}/dispersion_20240101.nc'\n",
    "\n",
    "# open check out metadata of each file\n",
    "ds_s = xr.open_dataset(file_s)\n",
    "ds_b = xr.open_dataset(file_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d894a-a1d0-457f-80dc-0a9d94d720be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea935ff3-3d10-4c7a-8a1c-d089df0309f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a37bd-1218-4096-bd68-f85e12dbf566",
   "metadata": {},
   "source": [
    "## Calculate derived metadata using original metadata above to create coordinates\n",
    "### We'll use this for creating our visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488084c-f982-4d03-ab25-7c81679aef1c",
   "metadata": {},
   "source": [
    "#### Calculate latitude and longitude grid for each set of files' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8287e0-dd1b-486a-850f-4ac8f229a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata to compute lon and lat\n",
    "longitude_s = np.linspace(ds_s.XORIG, ds_s.XORIG + ds_s.XCELL * (ds_s.NCOLS - 1), ds_s.NCOLS)\n",
    "latitude_s = np.linspace(ds_s.YORIG, ds_s.YORIG + ds_s.YCELL * (ds_s.NROWS - 1), ds_s.NROWS)\n",
    "\n",
    "longitude_b = np.linspace(ds_b.XORIG, ds_b.XORIG + ds_b.XCELL * (ds_b.NCOLS - 1), ds_b.NCOLS)\n",
    "latitude_b = np.linspace(ds_b.YORIG, ds_b.YORIG + ds_b.YCELL * (ds_b.NROWS - 1), ds_b.NROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92596e1d-7394-493c-9b77-74c0a6358cbd",
   "metadata": {},
   "source": [
    "#### The timestamps used in the files may not be intuitive. The following utility function returns the desired pandas timestamp based on your date and time of interest. \n",
    "\n",
    "##### When you index the data at a desired time, use this function to get the timestamp you need to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca4f7c-43fa-4bf8-ad57-daa9a6e1d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tflag(tflag):\n",
    "    \"\"\"\n",
    "    Return the tflag as a datetime object\n",
    "    :param list tflag: a list of two int32, the 1st representing date and 2nd representing time\n",
    "    \"\"\"\n",
    "    # obtain year and day of year from tflag[0] (date)\n",
    "    date = int(tflag[0])\n",
    "    year = date // 1000 # first 4 digits of tflag[0]\n",
    "    day_of_year = date % 1000 # last 3 digits of tflag[0]\n",
    "\n",
    "    # create datetime object representing date\n",
    "    final_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=day_of_year - 1)\n",
    "\n",
    "    # obtain hour, mins, and secs from tflag[1] (time)\n",
    "    time = int(tflag[1])\n",
    "    hours = time // 10000 # first 2 digits of tflag[1]\n",
    "    minutes = (time % 10000) // 100 # 3rd and 4th digits of tflag[1] \n",
    "    seconds = time % 100  # last 2 digits of tflag[1]\n",
    "\n",
    "    # create final datetime object\n",
    "    full_datetime = datetime.datetime(year, final_date.month, final_date.day, hours, minutes, seconds)\n",
    "    return full_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488bbfc-06ef-407d-953d-5266255e00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(year, month, day, hour):\n",
    "    \"\"\"\n",
    "    return a pandas timestamp using the given date-time arguments\n",
    "    :param int year: year\n",
    "    :param int month: month\n",
    "    :param int day: day\n",
    "    :param int hour: hour\n",
    "    \"\"\"\n",
    "    # Convert year, month, day, and hour to a datetime object\n",
    "    full_datetime = datetime.datetime(year, month, day, hour)\n",
    "    \n",
    "    # Extract components from the datetime object\n",
    "    year = full_datetime.year\n",
    "    day_of_year = full_datetime.timetuple().tm_yday\n",
    "    hours = full_datetime.hour\n",
    "    minutes = full_datetime.minute\n",
    "    seconds = full_datetime.second\n",
    "\n",
    "    # Compute tflag[0] and tflag[1]\n",
    "    tflag0 = year * 1000 + day_of_year\n",
    "    tflag1 = hours * 10000 + minutes * 100 + seconds\n",
    "\n",
    "    # Return the Pandas Timestamp object\n",
    "    return pd.Timestamp(full_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf7b30-a4d7-42e2-acbf-5609e14584c0",
   "metadata": {},
   "source": [
    "## Import sequence of data slices to get at what time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc32aa-c8bf-41c0-96b3-f2c23aeb029e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load idx_calls from file\n",
    "with open('idx_calls_v4.pkl', 'rb') as f:\n",
    "    idx_calls = pickle.load(f)\n",
    "\n",
    "print(len(idx_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb5f3-d231-4fe7-8be6-69c53e78df99",
   "metadata": {},
   "source": [
    "## Create the video\n",
    "### note: ffmpeg needs to be installed for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4f35e-eb0a-4e60-86aa-018cd76ea290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save frames\n",
    "folder = \"/usr/sci/scratch_nvme/arleth/dump/netcdf_frames\"\n",
    "\n",
    "# set parameters for creating visualization of each timestep with matplotlib\n",
    "my_norm = \"log\"\n",
    "my_extent_s = [np.min(longitude_s), np.max(longitude_s), np.min(latitude_s), np.max(latitude_s)]\n",
    "my_extent_b = [np.min(longitude_b), np.max(longitude_b), np.min(latitude_b), np.max(latitude_b)]\n",
    "my_aspect = 'auto'\n",
    "my_origin = 'lower'\n",
    "my_cmap = 'hot'\n",
    "\n",
    "# to keep track of files with 'issues'\n",
    "issue_files = {}\n",
    "\n",
    "# to track what frame we're on\n",
    "frame_num = 0\n",
    "\n",
    "# for all timesteps create visualization of firesmoke at time\n",
    "for call in tqdm(idx_calls):\n",
    "    # get instructions from call\n",
    "    # [curr_id, file_str, parse_tflag(ds['TFLAG'].values[tstep_idx][0]), tstep_idx]\n",
    "    curr_id = call[0]\n",
    "    curr_file = call[1]\n",
    "    curr_date = call[2]\n",
    "    tstep_index = call[3]\n",
    "    \n",
    "    # create visualization using matplotlib and cartopy geography lines, \n",
    "    # open the current file with xarray\n",
    "    ds = xr.open_dataset(f'{netcdf_dir}/{curr_id}/{curr_file}')\n",
    "\n",
    "    # Get the PM25 values, squeeze out empty axis\n",
    "    ds_vals = np.squeeze(ds['PM25'].values)\n",
    "\n",
    "    # get pm25 values at tstep_index and visualize them\n",
    "    data_at_time = ds_vals[tstep_index]\n",
    "\n",
    "    # get the timestamp for titling our plot, use hour 'h'\n",
    "    t = pd.Timestamp(parse_tflag(ds['TFLAG'].values[tstep_index][0]))\n",
    "    \n",
    "    # catch exceptions accordingly\n",
    "    try:\n",
    "        my_fig, my_plt = plt.subplots(figsize=(15, 6), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "        # extent is either with the 381x1041 lons/lats or 381x1081 lons/lats\n",
    "        curr_extent = my_extent_s if ds['PM25'].shape[3] == 1041 else my_extent_b\n",
    "        plot = my_plt.imshow(data_at_time, norm=my_norm, extent=curr_extent, aspect=my_aspect, origin=my_origin, cmap=my_cmap)\n",
    "        my_fig.colorbar(plot,location='right', label='ug/m^3')\n",
    "        my_plt.coastlines()\n",
    "        my_plt.gridlines(draw_labels=True)\n",
    "        # add a title with the time information\n",
    "        my_fig.suptitle(f'Ground Level Concentration of PM2.5 Microns and Smaller\\n{t}')\n",
    "        \n",
    "        # add an additional caption for context\n",
    "        my_plt.text(0.5, -0.1, 'Original NetCDF Data', ha='center', va='center', transform=my_plt.transAxes)\n",
    "        \n",
    "        # save the visualization as a frame\n",
    "        plt.savefig(folder + \"/frames%05d.png\" % frame_num, dpi=280)\n",
    "        plt.close(my_fig);  # Close the figure after saving\n",
    "        # plt.show()\n",
    "        matplotlib.pyplot.close()\n",
    "    except:\n",
    "        print(f\"issue! {t}\")\n",
    "        issue_files[t] = data_at_time\n",
    "        continue\n",
    "    # whether exception or not, next frame count to align with idx script\n",
    "    frame_num = frame_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa9100-8e6b-4573-bd6a-4dab86eb4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 'issue_files' to review\n",
    "with open('new_netcdf_issues.pkl', 'wb') as f:\n",
    "    pickle.dump(issue_files, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36186311-5405-4cf5-9ba9-9965f62f29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_netcdf_issues.pkl', 'rb') as f:\n",
    "    new_netcdf_issues = pickle.load(f)\n",
    "print(f'len of new_netcdf_issues.pkl = {len(new_netcdf_issues)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
