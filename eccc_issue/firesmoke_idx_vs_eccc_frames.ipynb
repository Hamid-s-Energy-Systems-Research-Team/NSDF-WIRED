{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217f49b7-528d-4384-aede-cc371224b9fd",
   "metadata": {},
   "source": [
    "# Create .PNG images of all timesteps in IDX firesmoke dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac89f1-da13-4a78-b05f-ac4a17fea961",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb7475-1c3d-41ef-92a2-dbaaaba8ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical work\n",
    "import numpy as np\n",
    "\n",
    "# for accessing file system\n",
    "import os\n",
    "\n",
    "# for downloading latest firesmoke netCDF\n",
    "import requests\n",
    "\n",
    "# for loading netcdf files, for metadata\n",
    "import xarray as xr\n",
    "# for connecting OpenVisus framework to xarray\n",
    "# from https://github.com/sci-visus/openvisuspy, \n",
    "from openvisuspy.xarray_backend import OpenVisusBackendEntrypoint\n",
    "\n",
    "# Used for processing netCDF time data\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Used for indexing via metadata\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# for exporting the dictionary of issue files at the end of notebook\n",
    "import pickle\n",
    "\n",
    "# Stores the OpenVisus cache in the local direcrtory \n",
    "import os\n",
    "os.environ[\"VISUS_CACHE\"]=\"./visus_cache_can_be_erased\"\n",
    "\n",
    "# Accessory, used to generate progress bar for running for loops\n",
    "# from tqdm.notebook import tqdm\n",
    "# import ipywidgets\n",
    "# import jupyterlab_widgets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from OpenVisus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dce7e-0bb4-459a-bf1f-85934fb960e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In this section, we load our data using `xr.open_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab5486-318a-4a2b-8af2-7fa89509b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to tiny NetCDF\n",
    "url = 'https://github.com/sci-visus/NSDF-WIRED/raw/main/data/firesmoke_metadata.nc'\n",
    "\n",
    "# # Download the file using requests\n",
    "# response = requests.get(url)\n",
    "local_netcdf = 'firesmoke_metadata.nc'\n",
    "# with open(local_netcdf, 'wb') as f:\n",
    "#     f.write(response.content)\n",
    "    \n",
    "# open tiny netcdf with xarray and OpenVisus backend\n",
    "ds = xr.open_dataset(local_netcdf, engine=OpenVisusBackendEntrypoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a37bd-1218-4096-bd68-f85e12dbf566",
   "metadata": {},
   "source": [
    "## Calculate derived metadata using original metadata above to create coordinates\n",
    "### This is required to allow for indexing of data via metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488084c-f982-4d03-ab25-7c81679aef1c",
   "metadata": {},
   "source": [
    "#### Calculate latitude and longitude grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8287e0-dd1b-486a-850f-4ac8f229a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata to compute lon and lat\n",
    "xorig = ds.XORIG\n",
    "yorig = ds.YORIG\n",
    "xcell = ds.XCELL\n",
    "ycell = ds.YCELL\n",
    "ncols = ds.NCOLS\n",
    "nrows = ds.NROWS\n",
    "\n",
    "longitude = np.linspace(xorig, xorig + xcell * (ncols - 1), ncols)\n",
    "latitude = np.linspace(yorig, yorig + ycell * (nrows - 1), nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627e8f5-b7df-4abc-aedf-8938bbebee29",
   "metadata": {},
   "source": [
    "#### Using calculated latitude and longitude, create coordinates allowing for indexing data using lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07279c-353b-4a74-a1ff-5c6543255a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create coordinates for lat and lon (credit: Aashish Panta)\n",
    "ds.coords['lat'] = ('ROW', latitude)\n",
    "ds.coords['lon'] = ('COL', longitude)\n",
    "\n",
    "# Replace col and row dimensions with newly calculated lon and lat arrays (credit: Aashish Panta)\n",
    "ds = ds.swap_dims({'COL': 'lon', 'ROW': 'lat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10061631-88f9-4abc-9270-ed1e80312346",
   "metadata": {},
   "source": [
    "##### Return an array of the tflags as pandas timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9322820-b096-4829-878a-efa3fbb2368b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_tflag(tflag):\n",
    "    \"\"\"\n",
    "    Return the tflag as a datetime object\n",
    "    :param list tflag: a list of two int32, the 1st representing date and 2nd representing time\n",
    "    \"\"\"\n",
    "    # obtain year and day of year from tflag[0] (date)\n",
    "    date = int(tflag[0])\n",
    "    year = date // 1000 # first 4 digits of tflag[0]\n",
    "    day_of_year = date % 1000 # last 3 digits of tflag[0]\n",
    "\n",
    "    # create datetime object representing date\n",
    "    final_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=day_of_year - 1)\n",
    "\n",
    "    # obtain hour, mins, and secs from tflag[1] (time)\n",
    "    time = int(tflag[1])\n",
    "    hours = time // 10000 # first 2 digits of tflag[1]\n",
    "    minutes = (time % 10000) // 100 # 3rd and 4th digits of tflag[1] \n",
    "    seconds = time % 100  # last 2 digits of tflag[1]\n",
    "\n",
    "    # create final datetime object\n",
    "    full_datetime = datetime.datetime(year, final_date.month, final_date.day, hours, minutes, seconds)\n",
    "    return full_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb823ce-6177-4a02-a86d-9a487fe2f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tflags\n",
    "tflag_values = ds['TFLAG'].values\n",
    "\n",
    "# to store pandas timestamps\n",
    "timestamps = []\n",
    "\n",
    "# convert all tflags to pandas timestamps, store in timestamps list\n",
    "for tflag in tflag_values:\n",
    "    timestamps.append(pd.Timestamp(parse_tflag(tflag[0])))\n",
    "\n",
    "# check out the first 3 timestamps\n",
    "timestamps[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80972a21-4958-48a8-a411-98e7a0f3f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set coordinates to each timestep with these pandas timestamps\n",
    "ds.coords['time'] = ('time', timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c46aa-7e57-4dc6-b62e-b91720fb0744",
   "metadata": {},
   "source": [
    "### Load the ECCC data, generated as in `eccc_data_clean.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7595d49-b6f6-4728-b3c5-dd5959de1677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eccc = pd.read_csv('PM25_2021_2022.csv')\n",
    "eccc_lons = df_eccc['Longitude//Longitude'].values\n",
    "eccc_lats = df_eccc['Latitude//Latitude'].values\n",
    "eccc_dates = df_eccc['Date//Date'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0da8ae-acfc-43e4-8b75-0eda1a2f1b0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create set of all hours to query for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a720a-ad62-43e7-a456-475d40e671af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = []\n",
    "for d in eccc_dates:\n",
    "    for i in range(24):\n",
    "        all_dates.append(pd.Timestamp(f'{d} {i}:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6e83e-bcc6-4200-964e-0b4b274a7e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in enumerate(all_dates[0:5]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa1476-54a0-4e17-b347-464fb146abdf",
   "metadata": {},
   "source": [
    "### Get IDX forecast at points closest to ECCC points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a59bab-56d1-4e1c-94db-598ef0ebbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nearest lat, lon values in idx to eccc lat, lon values\n",
    "data_resolution = 0\n",
    "ds_eccc_pts = ds.loc[dict(resolution=data_resolution)].sel(\n",
    "    lat=eccc_lats, lon=eccc_lons, method='nearest')\n",
    "\n",
    "# loop thru the coords, populate array with coord vals and pm25 vals\n",
    "idx_coords = np.column_stack([ds_eccc_pts.lat.values, ds_eccc_pts.lon.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58390fc3-b3b6-4f17-a766-13bac7b654e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_lats = idx_coords[:, 0]\n",
    "idx_lons = idx_coords[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb5f3-d231-4fe7-8be6-69c53e78df99",
   "metadata": {},
   "source": [
    "## Create the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81f990-8d5a-4dc7-b26a-c3e18be08184",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ds_idx['PM25'].sel(time=curr_date, lat=lat, \n",
    "            lon=lon, resolution=data_resolution).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d5914-d54b-4a1e-bd19-4581cedb6822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oh = ds['PM25'].sel(time=all_dates[2000], lat=idx_lats, lon=idx_lons, resolution=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3918b1e-afb8-4224-93b7-5ecad2c59608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oh.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052c0bb-9667-454f-a347-b4b7a7ae3ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbc300-7eea-40ef-9e53-0c69276503c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set parameters for creating visualization of each timestep with matplotlib\n",
    "my_norm = \"log\"\n",
    "my_extent = [np.min(eccc_lons), np.max(eccc_lons), np.min(eccc_lats), np.max(eccc_lats)]\n",
    "my_aspect = 'auto'\n",
    "my_origin = 'lower'\n",
    "my_cmap = 'autumn'\n",
    "my_vmin = 1e-13\n",
    "my_vmax = 10e4\n",
    "fig_w, fig_h = 15, 6\n",
    "issue_files = {}\n",
    "full_data = False\n",
    "if full_data:\n",
    "    save_dir = \"/usr/sci/scratch_nvme/arleth/dump/idx_vs_eccc_frames/full_data/\"\n",
    "else:\n",
    "    save_dir = \"/usr/sci/scratch_nvme/arleth/dump/idx_vs_eccc_frames/point_data/\"\n",
    "\n",
    "\n",
    "def create_frame_catch_issues(frame_date_tuple):\n",
    "    # frame number to save PNG as and date to visualize\n",
    "    frame_num = frame_date_tuple[0]\n",
    "    date = frame_date_tuple[1]\n",
    "\n",
    "    # # create visualization using matplotlib and cartopy geography lines\n",
    "    # try: # visualize data if it's available\n",
    "    data_array_at_time = None\n",
    "\n",
    "    # set up visualization\n",
    "    my_fig, my_plt = plt.subplots(figsize=(fig_w, fig_h), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    my_plt.coastlines()\n",
    "    my_plt.gridlines(draw_labels=True)\n",
    "    my_fig.suptitle(f'Ground level concentration of PM2.5 microns and smaller {date}\\n')\n",
    "\n",
    "    if full_data:# get PM25 values and provide 4 values, the colons mean select all lat and lon indices\n",
    "        data_array_at_time = ds['PM25'].loc[date, :, :, data_resolution]\n",
    "        plot = my_plt.imshow(data_array_at_time, extent=my_extent,\n",
    "                         aspect=my_aspect, origin=my_origin, cmap=my_cmap,\n",
    "                         norm=my_norm, vmax=my_vmax, vmin=my_vmin)\n",
    "    else:\n",
    "        data_array_at_time = ds['PM25'].loc[date, :, :, data_resolution]\n",
    "        my_plt.set_extent(my_extent, crs=ccrs.PlateCarree())\n",
    "        my_plt.set_aspect('auto')\n",
    "        # get the values for the given hour and get latitudes and longitudes for plotting\n",
    "        curr_vals = data_array_at_time.values.flatten()\n",
    "        curr_lats = eccc_lats\n",
    "        curr_lons = eccc_lons\n",
    "\n",
    "        plot = my_plt.scatter(curr_lons, curr_lats, c=curr_vals, cmap=my_cmap,\n",
    "                                 norm=my_norm, s=5, transform=ccrs.PlateCarree(),\n",
    "                                 vmin=my_vmin, vmax=my_vmax)\n",
    "\n",
    "    my_fig.colorbar(plot, location='right', label='ug/m^3')\n",
    "    # add caption showing this is from IDX dataset\n",
    "    plt.text(0.5, -0.1, 'IDX Data', ha='center', va='center', transform=my_plt.transAxes)\n",
    "\n",
    "    # save visualization as a .PNG to our folder\n",
    "    plt.savefig(save_dir + \"frames%05d.png\" % frame_num, dpi=280)\n",
    "    plt.close(my_fig);  # close the figure after saving\n",
    "    matplotlib.pyplot.close()\n",
    "    # my_plt.show()\n",
    "    # except: # return empty image otherwise\n",
    "    #     fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    #     ax.axis('off')\n",
    "    #     plt.text(.5, .5, 'IDX Data UNAVAILABLE', fontsize=20, horizontalalignment='center',\n",
    "    #  verticalalignment='center',)\n",
    "    #     # save visualization as a .PNG to our folder\n",
    "    #     plt.savefig(save_dir + \"frames%010d.png\" % frame_num, dpi=280)\n",
    "    #     plt.close(fig);  # close the figure after saving\n",
    "    #     # plt.show()\n",
    "    #     return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9d45-a5d5-4163-9003-5a5d15e5841a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proc_lim = 10\n",
    "# create frames, capturing issues \n",
    "with multiprocessing.Pool(processes=proc_lim) as pool:\n",
    "    # Start a timer to measure how long the conversion takes\n",
    "    start_time = time.time()\n",
    "    print('starting')\n",
    "    issues = pool.map(create_frame_catch_issues, enumerate([all_dates[2000]]))\n",
    "    print('done!')\n",
    "    # End the timer and print the elapsed time\n",
    "    end_time = time.time()\n",
    "    print(f'Total elapsed time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb7afe-5960-4fee-aec8-b815c34c2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 'issue_files' to review\n",
    "with open('new_idx_issues.pkl', 'wb') as f:\n",
    "    pickle.dump(issue_files, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e20ec-4e42-456e-8ec8-e987ccefe289",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_idx_issues.pkl', 'rb') as f:\n",
    "    new_idx_issues = pickle.load(f)\n",
    "print(f'len of new_idx_issues.pkl = {len(new_idx_issues)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0ae6c-2ef1-46b6-b440-a345380fa4d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### old basemap attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de70278-084e-4c47-b47c-6181c0be94e6",
   "metadata": {},
   "source": [
    "Get latitude and longitude values to use basemap to plot them with corresponding PM2.5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4abd1b-83df-47f7-8bda-5347c8fca980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # populate these with all coordinates and values at current tstep\n",
    "# # get PM25 values and provide 4 values, the colons mean select all lat and lon indices\n",
    "# curr_ds = ds['PM25'].loc[0, :, :, 0]\n",
    "# arr_size = ds.sizes['lat'] * ds.sizes['lon']\n",
    "# lons = np.zeros(arr_size)\n",
    "# lats = np.zeros(arr_size)\n",
    "# vals = np.zeros(arr_size)\n",
    "# c = 0\n",
    "\n",
    "# for i in np.arange(ds.sizes['lat']):\n",
    "#     for j in np.arange(ds.sizes['lon']):\n",
    "#         lats[c] = curr_ds.lat.values[i]\n",
    "#         lons[c] = curr_ds.lon.values[j]\n",
    "#         vals[c] = curr_ds.values[i][j]\n",
    "#         c += 1\n",
    "# a = lons\n",
    "# b = lats\n",
    "# c = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e453afb-0844-4583-a77c-c6bdc4bbb253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_resolution = 0\n",
    "# save_dir = \"/usr/sci/scratch_nvme/arleth/dump/idx_vs_eccc_frames/\"\n",
    "# issue_files = {}\n",
    "\n",
    "# def create_frame_catch_issues(tstep):\n",
    "#     # get PM25 values and provide 4 values, the colons mean select all lat and lon indices\n",
    "#     curr_ds = ds['PM25'].loc[tstep, :, :, data_resolution]\n",
    "    \n",
    "#     # populate these with all coordinates and values at current tstep\n",
    "#     arr_size = ds.sizes['lat'] * ds.sizes['lon']\n",
    "#     lons = np.zeros(arr_size)\n",
    "#     lats = np.zeros(arr_size)\n",
    "#     vals = np.zeros(arr_size)\n",
    "#     c = 0\n",
    "    \n",
    "#     for i in np.arange(ds.sizes['lat']):\n",
    "#         for j in np.arange(ds.sizes['lon']):\n",
    "#             lats[c] = curr_ds.lat.values[i]\n",
    "#             lons[c] = curr_ds.lon.values[j]\n",
    "#             vals[c] = curr_ds.values[i][j]\n",
    "#             c += 1\n",
    "#     # # create visualization using matplotlib and cartopy geography lines, \n",
    "#     # # catch exceptions accordingly\n",
    "#     # try:\n",
    "#     # use basemap to plot values: https://basemaptutorial.readthedocs.io/en/latest/plotting_data.html#scatter\n",
    "#     # use `cyl` project: https://matplotlib.org/basemap/stable/users/cyl.html\n",
    "#     # set parameters: https://basemaptutorial.readthedocs.io/en/latest/basemap.html\n",
    "#     m = Basemap(projection='cyl', llcrnrlat=np.min(lats),urcrnrlat=np.max(lats),\n",
    "#             llcrnrlon=np.min(lons),urcrnrlon=np.max(lons), lat_0=51, lon_0=-106, resolution='l',\n",
    "#             fix_aspect=False, area_thresh=1e6)\n",
    "\n",
    "#     # Draw map features\n",
    "#     m.drawcoastlines()\n",
    "#     # m.drawparallels(np.arange(45.,66.,5.),labels=[1,1,1,1]) # draw parallels\n",
    "#     # m.drawmeridians(np.arange(-120.,-59.,20.),labels=[1,1,1,1]) # draw parallels\n",
    "\n",
    "#     # Convert lat/lon to map coordinates for Basemap scatter plot\n",
    "#     x, y = m(lons, lats)\n",
    "\n",
    "#     # Plot the lats and lons\n",
    "#     m.scatter(x, y, marker=',', s=.001, c=vals, cmap='hot')\n",
    "#     plt.show()\n",
    "#     # except:\n",
    "#     #     t = pd.Timestamp(parse_tflag(ds.TFLAG[tstep][0]))\n",
    "#     #     print(f\"issue! {t}\")\n",
    "#     #     return t, curr_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
