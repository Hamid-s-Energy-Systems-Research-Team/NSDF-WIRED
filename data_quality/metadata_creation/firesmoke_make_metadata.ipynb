{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac25998-cfa8-4666-8a19-247586c526ee",
   "metadata": {},
   "source": [
    "# Here we're making arrays holding metadata for idx conversion v4\n",
    "## In particular we get:\n",
    "- Timestamp of each datum\n",
    "- Boolean representing if datum was resampled from 1041x381 to 1081x381 grid\n",
    "- Timestamp of each datum's last [WRF-ARW weather forecast initialization](https://firesmoke.ca/resources/BSC-2015ForecastScheduleV6.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b06a1-6ad9-4da6-b346-5361a4c03b8c",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b73e96-27fd-4a23-b378-12ce04b5324b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Used to read/manipulate netCDF data\n",
    "import xarray as xr\n",
    "\n",
    "# Used for interacting with OS file system (to get directory file names)\n",
    "import os\n",
    "\n",
    "# Used for processing netCDF time data\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Used for numerical work\n",
    "import numpy as np\n",
    "\n",
    "# Used for loading data from pickle data\n",
    "import pickle\n",
    "\n",
    "# Accessory for generating progress bar to see progress of loops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6561cb-f86e-429d-b95d-6c68a5e29f08",
   "metadata": {},
   "source": [
    "## Import sequence of IDX calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65eb4d8-3fe1-4266-b984-235323f3bc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy and paste .pkl file into working directory\n",
    "with open(\"idx_calls_v4.pkl\", \"rb\") as input_file:\n",
    "    idx_calls = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66ed18-dbb1-4f8c-abf8-d8ab5b5dd0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca5a13-ab4a-404e-97f3-72e7281a6519",
   "metadata": {},
   "source": [
    "Location of all netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72816ed-748b-4cd5-a904-60b5ba747e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# location of netCDF files\n",
    "firesmoke_dir = \"/usr/sci/cedmav/data/firesmoke\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc76787-8834-432d-a8d7-203f8d3ff005",
   "metadata": {},
   "source": [
    "## Step through all `idx_calls` and obtain metadata.\n",
    "\n",
    "### Specifically we:\n",
    "1. Get timestamps as saved in `idx_calls`.\n",
    "2. Get grid size from original netCDF files.\n",
    "3. Get last initialized time as shown in `idx_calls`.\n",
    "---\n",
    "These instructions could have been run during the IDX conversion. However I decided to do it separately by stepping through the `idx_calls` sequence so the IDX conversion loop would not be so bloated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5c184-b5a1-458f-b2e4-3b70d8ad3925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtaining the preferred tflag based on original metadata\n",
    "def reverse_parse_tflag(full_datetime):\n",
    "    '''\n",
    "    Return the UBC style tflag for given datetime stamp\n",
    "    :param datetime full_datetime: full datetime object containing the year, day, hour, minute, and second\n",
    "    :return: tuple containing two tflags, where the first represents the year and day of the year,\n",
    "             and the second represents the hour, minute, and second\n",
    "    '''\n",
    "    year = full_datetime.year\n",
    "    day_of_year = full_datetime.timetuple().tm_yday\n",
    "    hours = full_datetime.hour\n",
    "    minutes = full_datetime.minute\n",
    "    seconds = full_datetime.second\n",
    "\n",
    "    tflag0 = year * 1000 + day_of_year\n",
    "    tflag1 = hours * 10000 + minutes * 100 + seconds\n",
    "\n",
    "    return tflag0, tflag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121555a-4e3f-4427-ab81-27216cd6e211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_last_timestamp(id_, file):\n",
    "    '''\n",
    "    Return datetime stamp of the last forecast update seen for the given dataset ID and file name.\n",
    "    :param str id_: The dataset ID used\n",
    "    :param str file: The name of the file, with the date\n",
    "    '''\n",
    "    # use file's date\n",
    "    date = datetime.datetime.strptime(file[-len('20210304.nc'):-len('.nc')], \"%Y%m%d\")\n",
    "    \n",
    "    # set hour of intialization based on dataset ID\n",
    "    if id_ == \"BSC18CA12-01\":\n",
    "        date = date.replace(hour=18)\n",
    "    if id_ == \"BSC00CA12-01\": \n",
    "        date = date.replace(hour=0)\n",
    "    if id_ == \"BSC06CA12-01\":\n",
    "        date = date.replace(hour=6)\n",
    "    if id_ == \"BSC12CA12-01\":\n",
    "        date = date.replace(hour=12)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef02cd8-c385-4480-acbd-d768d949553f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the final array of UBC style tflags\n",
    "tflags = []\n",
    "\n",
    "# whether resampled or not\n",
    "is_resampled = []\n",
    "\n",
    "# hold the timestamp of when each timestamp saw it's last forecast initialization\n",
    "last_init = []\n",
    "\n",
    "# hold the attributes for each file, TODO NEED TO CONFIRM WHAT THEY ARE?, SEEMS USEFUL ATTRS\n",
    "attrs_desired = ['CDATE', 'CTIME', 'WDATE', 'WTIME', 'SDATE', 'STIME']\n",
    "\n",
    "attr_data = {attr: [] for attr in attrs_desired}\n",
    "\n",
    "# create array of UBC style tflags from our sequence of idx_calls\n",
    "for call in tqdm(idx_calls):\n",
    "    # get instructions from call, call looks like:\n",
    "    # [curr_id, file_str, parse_tflag(ds['TFLAG'].values[tstep_idx][0]), tstep_idx]\n",
    "    curr_id = call[0]\n",
    "    curr_file = call[1]\n",
    "    curr_tflag = call[2]\n",
    "    tstep_index = call[3]    \n",
    "\n",
    "    # open the file with xarray\n",
    "    ds = xr.open_dataset(f'{firesmoke_dir}/{curr_id}/{curr_file}')\n",
    "    \n",
    "    # resample data if not already on max lat/lon grid\n",
    "    is_resampled.append(ds.XORIG != -160.0)\n",
    "\n",
    "    # make UBC style tflag and append to our final array\n",
    "    tflags.append(reverse_parse_tflag(curr_tflag))\n",
    "\n",
    "    # get UBC style tflag of last forecast update time\n",
    "    last_timestamp = get_last_timestamp(curr_id, curr_file)\n",
    "    last_init.append(reverse_parse_tflag(last_timestamp))\n",
    "    \n",
    "    # save the attribute information to the arrays\n",
    "    for attr in attrs_desired:\n",
    "        attr_data[attr].append(ds.attrs[attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777c92b-545c-4bbc-bb9b-5a507726f390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save all arrays, the metadata\n",
    "np.save('firesmoke_v4-tflags.npy', tflags)\n",
    "np.save('firesmoke_v4-resamp.npy', is_resampled)\n",
    "np.save('firesmoke_v4-last_init.npy', last_init)\n",
    "\n",
    "for attr in attrs_desired:\n",
    "    np.save(f'firesmoke_v4-{attr}.npy', attr_data[attr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
